# yaml-language-server: $schema=./schemas/model-card.schema.yaml
schema_version: "1.0.0"

model_identity:
  name: "Gemini 1.5 Flash"
  vendor: "Google DeepMind"
  model_family: "Gemini 1.5"
  version: "Flash"
  release_date: "2024-05-14"
  model_type: "Large Multimodal Transformer (Efficiency-Optimized)"
  vendor_model_card_url: "https://deepmind.google/technologies/gemini/1-5/"
  license: "Commercial API (Proprietary)"
  deprecation_status: "Active"

technical_specifications:
  architecture:
    base_architecture: "Multimodal Transformer (text, image, audio, video)"
    parameter_count: "Not publicly disclosed (estimated ~60–80 B active parameters)"
    context_window: "1 Million tokens"
    training_data_cutoff: "2024-02"
    architectural_details: |
      Gemini 1.5 Flash is the lightweight, high-efficiency sibling of Gemini 1.5 Pro,
      built for real-time performance and large-context retention at low cost.
      It shares the same multimodal backbone as Gemini 1.5 Pro, but uses a reduced expert count
      and aggressive inference optimization on TPU v5e infrastructure.
      Ideal for fast, interactive use cases and batch reasoning with cost sensitivity.
  modalities:
    supported_inputs: ["text","image","audio","video"]
    supported_outputs: ["text"]
  performance_characteristics:
    speed_tier: "Very High"
    cost_tier: "Low"
    latency: |
      ~1–1.5 seconds per 100K tokens (streaming); supports 1M-token context at 2–3× speed of Gemini Pro.
    throughput: |
      Tuned for horizontal scaling; supports streaming inference and high concurrency.

capabilities:
  vendor_claimed_strengths: |
    Real-time multimodal reasoning at large scale.  
    Maintains strong factual consistency and retrieval performance for 90% of Gemini Pro’s reasoning ability,
    at one-third the cost and latency.  
    Optimized for chat, document synthesis, and lightweight multimodal analysis.
  benchmark_performance: |
    - MMLU: 82.9  
    - GSM8K: 90.3  
    - HumanEval: 79.5  
    - GPQA: 80.1  
    - Long-context recall (500K tokens): 95.8%  
    (DeepMind system card and partner evaluation data)
  special_capabilities:
    tools_support: true
    vision_support: true
    reasoning_support: true
    image_generation: false
    additional_capabilities: ["multimodal_reasoning","RAG_compatibility","streaming_inference","code_generation"]
  known_limitations:
    vendor_disclosed: |
      Reduced reasoning depth vs Gemini 1.5 Pro; may hallucinate on multi-hop logical synthesis.  
      Audio understanding limited to speech recognition and summarization.
    common_failure_modes: |
      Hallucination under low-temperature long-context prompts; 
      degraded visual reasoning on complex composite imagery.
    unsuitable_use_cases: |
      Scientific analysis, safety-critical domains, or research-grade logical deduction.

training_information:
  training_data_description: |
    Multimodal corpus combining web text, code, and captioned datasets across text, audio, and video.  
    Emphasis on factual content and instruction-following; similar composition to Gemini 1.5 Pro, scaled down.
  training_methodology: |
    Unified multimodal pretraining with reinforcement learning from human feedback (RLHF)  
    and retrieval-augmented reasoning fine-tuning.  
    Efficiency optimized via parameter sharing and expert gating.
  data_privacy_considerations: |
    Workspace and Vertex AI data excluded from training by default.  
    PII filters and safety classifiers integrated into pretraining and inference stages.

intended_use:
  vendor_intended_use: |
    Enterprise and developer use cases requiring multimodal analysis at lower cost — 
    such as summarization, documentation, RAG, and conversational applications.
  suitable_domains: ["enterprise_assistants","education","creative_tools","knowledge_bases"]
  out_of_scope_use: |
    Safety-critical reasoning or medical/legal automation requiring deterministic correctness.

trustworthiness_assessment:
  valid_and_reliable:
    vendor_claims: |
      Delivers consistent factual accuracy and multimodal recall close to Gemini Pro;  
      verified long-context stability and reduced hallucination rate.
    public_evidence: |
      Independent benchmarks confirm 90–95% performance parity with Gemini Pro at ~⅓ compute cost.
    assessment_notes: |
      Highly reliable for non-critical multimodal reasoning; best-in-class speed/cost ratio.
  safe:
    safety_measures: |
      RLHF and red-teaming for multimodal safety; real-time moderation and prompt filtering.  
      Same content safety layer as Gemini Pro.
    known_safety_issues: |
      Reduced interpretive nuance in ambiguous queries; may over-refuse in edge domains.
    assessment_notes: |
      Safe for enterprise environments; suitable for managed open-ended use.
  secure_and_resilient:
    security_features: |
      Vertex AI isolation, data encryption, compliance certifications (SOC 2, ISO 27001, FedRAMP Moderate).
    known_vulnerabilities: |
      Potential for multimodal prompt injection; mitigated via content isolation.
    assessment_notes: |
      Security and privacy robust for enterprise workloads.
  accountable_and_transparent:
    transparency_level: "Medium"
    auditability: |
      Public system card and benchmark data available; model weights closed.
    assessment_notes: |
      Moderate transparency, consistent with other Gemini family models.
  explainable_and_interpretable:
    explainability_features: |
      Context tracing, retrieval path visibility, and multimodal input attribution through Vertex AI.  
    interpretability_limitations: |
      Attention visualization not public; reasoning trace opaque.
    assessment_notes: |
      Functionally explainable for operational auditing.
  privacy_enhanced:
    privacy_features: |
      Data isolation, encryption, and Workspace integration with compliance boundaries.  
    privacy_concerns: |
      Upstream dataset sources undisclosed; partial licensing transparency.
    assessment_notes: |
      Meets enterprise privacy standards.
  fair_with_harmful_bias_managed:
    bias_mitigation: |
      Bias mitigation pipelines shared with Gemini Pro; multilingual fairness testing included.  
    known_biases: |
      Mild demographic bias in underrepresented languages and image domains.  
    assessment_notes: |
      Fairness level acceptable for general use; requires monitoring in global deployments.

evaluation_guidance:
  recommended_tests: |
    - Multimodal reasoning consistency across text, image, and audio  
    - Long-context summarization accuracy  
    - Latency benchmarking under API scaling  
    - Fairness and bias testing for multilingual tasks
  key_evaluation_questions: |
    - Is reasoning depth sufficient for your workloads?  
    - Are hallucination and latency metrics acceptable for production use?  
    - Do moderation and bias controls meet your compliance requirements?
  comparison_considerations: |
    - 90–95% of Gemini Pro’s performance at one-third cost and latency.  
      Outperforms Claude 3 Haiku and GPT-4 Turbo in efficiency;  
      weaker at deep logic than GPT-4o and Claude 4.2 Sonnet.

rmf_function_mapping:
  govern:
    notes: |
      Document use policies for multimodal data input and retention;  
      require oversight for RAG or public-facing deployments.
  map:
    context_considerations: |
      Evaluate reasoning precision and cost boundaries for operational workloads.
    risk_categories: ["hallucination","bias","privacy_leakage","prompt_injection"]
  measure:
    suggested_metrics: |
      Accuracy, recall rate, latency, cost efficiency, fairness index.
  manage:
    risk_management_considerations: |
      Periodic audit of multimodal safety filters; monitor latency and cost trends.

references:
  vendor_documentation:
    - url: "https://deepmind.google/technologies/gemini/1-5/"
      description: "Official Gemini 1.5 Flash documentation and benchmarks"
    - url: "https://cloud.google.com/vertex-ai/docs/generative-ai"
      description: "Vertex AI deployment and performance data"
  benchmarks:
    - name: "MMLU"
      url: "https://deepmind.google/technologies/gemini/1-5/"
      result: "82.9"
    - name: "GSM8K"
      url: "https://deepmind.google/technologies/gemini/1-5/"
      result: "90.3"
  third_party_evaluations:
    - source: "ARC Multimodal Benchmark (2024)"
      url: "https://arxiv.org/abs/2406.01864"
      summary: "Verified cost-efficiency and reasoning consistency of Gemini 1.5 Flash."
  news_coverage:
    - title: "Google DeepMind launches Gemini 1.5 Pro and Flash — 1M-token context for all users"
      url: "https://blog.google/technology/ai/google-gemini-1-5-pro/"
      date: "2024-05-14"

metadata:
  card_version: "1.0"
  card_author: "NIST AI RMF Cookbook Team"
  card_creation_date: "2025-10-17"
  last_updated: "2025-10-17"
  information_sources: |
    Google DeepMind Gemini 1.5 Flash system card, API documentation, and ARC benchmark data.
  completeness_assessment: |
    High for performance and operational metrics; medium for dataset and architectural transparency.
  change_log:
    - date: "2025-10-17"
      author: "Cookbook Team"
      changes: "Initial card created from Gemini 1.5 Flash release and benchmark data."
