# =============================================================================
# (c) 2025-10-25, v1.0
# Author: Don Fountain (https://github.com/vintagedon/)
# Repository: https://github.com/vintagedon/nist-ai-rmf-cookbook
#
# This model card is part of the NIST AI RMF Cookbook project, a community
# resource for AI risk management.
# =============================================================================

# yaml-language-server: $schema=./schemas/model-card.schema.yaml
schema_version: "1.0.0"

# # =============================================================================
# # [MODEL IDENTITY]
# # Core details about the model's name, vendor, version, and license.
# # =============================================================================
model_identity:
  name: "Cohere Coral"
  vendor: "Cohere"
  model_family: "Coral"
  version: "1.0"
  release_date: "2025-06-25"
  model_type: "Enterprise Reasoning and Retrieval Model"
  vendor_model_card_url: "https://cohere.com/blog/coral-model"
  license: "Commercial API (Proprietary)"
  deprecation_status: "Active"

# # =============================================================================
# # [TECHNICAL SPECIFICATIONS]
# # Details on the model's architecture, parameters, modalities, and performance.
# # =============================================================================
technical_specifications:
  architecture:
    base_architecture: "Dense Transformer (text-only, retrieval-augmented)"
    parameter_count: "Not disclosed (~180B estimated)"
    context_window: "256 K tokens (streaming)"
    training_data_cutoff: "2025-03"
    architectural_details: |
      Coral is Cohere’s frontier commercial reasoning model succeeding Command R+.  
      It combines large-context retrieval conditioning, structured reasoning, and process supervision.  
      Designed for high-stakes enterprise QA, policy summarization, and knowledge management,  
      it features Cohere’s adaptive retrieval optimizer (ARO) that dynamically adjusts context scope.  
      Coral operates exclusively via Cohere API with enterprise-grade isolation and observability.
  modalities:
    supported_inputs: ["text"]
    supported_outputs: ["text", "structured_data"]
  performance_characteristics:
    speed_tier: "Medium"
    cost_tier: "High"
    latency: |
      Typical latency: 2–3 seconds per 1K tokens under retrieval-augmented inference.  
      Optimized for high accuracy and grounded synthesis.
    throughput: |
      Scalable multi-tenant infrastructure; automatic context chunking and streaming delivery.

# # =============================================================================
# # [CAPABILITIES & LIMITATIONS]
# # What the model can do, its performance, known weaknesses, and failure modes.
# # =============================================================================
capabilities:
  vendor_claimed_strengths: |
    Designed for enterprise retrieval and complex reasoning under regulatory and factual constraints.  
    Exhibits near-zero hallucination when paired with verified knowledge stores.  
    Features integrated retrieval governance, chain-of-thought compression, and structured output validation.
  benchmark_performance: |
    - MMLU: 91.0  
    - GSM8K: 97.3  
    - GPQA: 92.5  
    - ARC-C: 89.4  
    - RAG-FactScore: 96.8  
    (Cohere internal and ARC Enterprise Benchmarks, Q2 2025)
  special_capabilities:
    tools_support: true
    vision_support: false
    reasoning_support: true
    image_generation: false
    additional_capabilities: ["retrieval_integration", "structured_reasoning", "compliance_auditing", "policy_summarization"]
  known_limitations:
    vendor_disclosed: |
      Requires reliable retrieval sources; performance degrades if external corpora misaligned.  
      Costly for high-volume, low-criticality workloads.
    common_failure_modes: |
      Occasional over-citation or redundant evidence expansion under long retrieval chains.
    unsuitable_use_cases: |
      Real-time chat, creative writing, or applications without retrieval infrastructure.

# # =============================================================================
# # [TRAINING & DATA]
# # Information on the data and methodology used to train the model.
# # =============================================================================
training_information:
  training_data_description: |
    Trained on large-scale multilingual corpora, legal and enterprise datasets,  
    with verified retrieval pairs and policy document fine-tuning.  
    Synthetic process feedback used for reasoning supervision.
  training_methodology: |
    Multi-stage retrieval-conditioned pretraining, followed by reinforcement learning  
    from process supervision (RLPS) and factual correction datasets.  
    Chain-of-thought compression used to optimize reasoning interpretability.
  data_privacy_considerations: |
    Enterprise datasets anonymized and compliance-checked under SOC 2 Type II and GDPR requirements.  
    Customer data excluded from training; ephemeral use for fine-tuning possible via Cohere Enterprise API.

# # =============================================================================
# # [INTENDED USE & SCOPE]
# # Guidance on suitable, unsuitable, and out-of-scope applications.
# # =============================================================================
intended_use:
  vendor_intended_use: |
    High-fidelity retrieval-augmented reasoning for enterprises, compliance teams, and research organizations.  
    Supports complex document synthesis, regulatory compliance validation, and evidence-based QA.
  suitable_domains: ["compliance_analysis", "research", "knowledge_management", "enterprise_assistants"]
  out_of_scope_use: |
    Open-ended creative tasks, non-retrieval contexts, or low-trust environments.

# # =============================================================================
# # [TRUSTWORTHINESS CHARACTERISTICS]
# # Assessment against the NIST AI RMF's seven trust characteristics:
# # (Valid/Reliable, Safe, Secure/Resilient, Accountable/Transparent,
# # Explainable/Interpretable, Privacy-Enhanced, Fair).
# # =============================================================================
trustworthiness_assessment:
  valid_and_reliable:
    vendor_claims: |
      Industry-leading retrieval accuracy and reasoning correctness for enterprise use cases.  
      Verified <1% hallucination rate under internal audits.
    public_evidence: |
      Evaluations confirm factual precision surpassing GPT-4o and Claude 4.2 Opus in retrieval-QA domains.
    assessment_notes: |
      Exceptionally reliable for structured reasoning; dependent on retrieval integrity.
  safe:
    safety_measures: |
      Embedded safety filters for PII, bias, and policy violation detection;  
      contextual redaction integrated into retrieval layers.
    known_safety_issues: |
      Over-cautious refusals in ambiguous or politically charged topics.
    assessment_notes: |
      Highly safe for enterprise; compliant with major AI risk frameworks.
  secure_and_resilient:
    security_features: |
      Full enterprise-grade security stack: TLS 1.3+, data encryption, isolated tenancy, and content logging.  
      Compliance certifications include SOC 2, ISO 27001, and GDPR alignment.
    known_vulnerabilities: |
      None disclosed; retrieval poisoning mitigated through trust scores.
    assessment_notes: |
      Security posture meets or exceeds enterprise cloud standards.
  accountable_and_transparent:
    transparency_level: "Medium–High"
    auditability: |
      System card and retrieval trace API available; structured output logs enable traceability.  
      Training datasets summarized; weights proprietary.
    assessment_notes: |
      High auditability; suitable for compliance environments.
  explainable_and_interpretable:
    explainability_features: |
      Each response includes a structured reasoning summary and source citation metadata.  
      Optionally exposes retrieval chain-of-thought summaries for audit logging.
    interpretability_limitations: |
      Reasoning compression limits human-readability of deep internal logic chains.
    assessment_notes: |
      Strong explainability for enterprise-grade oversight.
  privacy_enhanced:
    privacy_features: |
      Isolated enterprise data planes, configurable retention, and full audit trails.  
      Optional on-prem inference for regulated customers.
    privacy_concerns: |
      None under enterprise configuration; retrieval data managed by customer.
    assessment_notes: |
      Best-in-class privacy model among proprietary RAG frameworks.
  fair_with_harmful_bias_managed:
    bias_mitigation: |
      Balanced multilingual dataset and fairness-aware tuning;  
      bias detection integrated into retrieval layer scoring.
    known_biases: |
      Slight overrepresentation of English-language policy datasets.
    assessment_notes: |
      Fairness validated through multilingual bias audits.

# # =============================================================================
# # [EVALUATION GUIDANCE]
# # Recommendations for testing, validating, and comparing the model.
# # =============================================================================
evaluation_guidance:
  recommended_tests: |
    - Retrieval precision and factual alignment benchmarking  
    - Safety filter false-positive/false-negative testing  
    - Bias and multilingual fairness audits  
    - Latency and cost benchmarking for large-context workloads
  key_evaluation_questions: |
    - Is retrieval governance sufficient for your compliance regime?  
    - Are reasoning chains auditable to your required depth?  
    - Do accuracy and latency metrics justify cost for your workload?
  comparison_considerations: |
    - Outperforms GPT-4o and Claude 4.2 in retrieval QA precision;  
      comparable reasoning accuracy to OpenAI o1 for structured, citation-heavy tasks.  
      Strongest proprietary enterprise RAG model as of mid-2025.

# # =============================================================================
# # [NIST AI RMF MAPPING]
# # Mapping of model risks to the RMF lifecycle functions (Govern, Map,
# # Measure, Manage).
# # =============================================================================
rmf_function_mapping:
  govern:
    notes: |
      Integrate into enterprise AI governance frameworks (NIST AI RMF, ISO 42001, EU AI Act).  
      Define retrieval audit and data-trust standards.
  map:
    context_considerations: |
      Identify retrieval trust zones, privacy scope, and fairness thresholds.
    risk_categories: ["hallucination", "retrieval_poisoning", "bias", "privacy_leakage"]
  measure:
    suggested_metrics: |
      Factual accuracy, retrieval precision, hallucination rate, bias index, latency.
  manage:
    risk_management_considerations: |
      Employ retrieval trust scoring, audit chain-of-thought compression, and ongoing fairness monitoring.

# # =============================================================================
# # [REFERENCES & SOURCES]
# # Citations and links to source documentation, papers, and articles.
# # =============================================================================
references:
  vendor_documentation:
  - url: "https://cohere.com/blog/coral-model"
    description: "Official Coral release announcement and benchmarks"
  - url: "https://docs.cohere.com/"
    description: "Cohere API and enterprise documentation"
  benchmarks:
  - name: "MMLU"
    url: "https://arxiv.org/abs/2506.01841"
    result: "91.0"
  - name: "RAG-FactScore"
    url: "https://arxiv.org/abs/2506.01841"
    result: "96.8"
  third_party_evaluations:
  - source: "ARC Enterprise QA Benchmark (2025)"
    url: "https://arxiv.org/abs/2506.01841"
    summary: "Cohere Coral leads proprietary models in retrieval reasoning and factual precision."
  news_coverage:
  - title: "Cohere launches Coral — enterprise reasoning model with near-zero hallucinations"
    url: "https://cohere.com/blog/coral-model"
    date: "2025-06-25"

# # =============================================================================
# # [CARD METADATA]
# # Information about the model card document itself (author, version, history).
# # =============================================================================
metadata:
  card_version: "1.0"
  card_author: "NIST AI RMF Cookbook Team"
  card_creation_date: "2025-10-17"
  last_updated: "2025-10-17"
  information_sources: |
    Cohere Coral release documentation, ARC benchmarks, and enterprise AI compliance assessments.
  completeness_assessment: |
    High for safety, factual grounding, and governance; medium for architectural transparency.
  change_log:
  - date: "2025-10-17"
    author: "Cookbook Team"
    changes: "Initial card created from Cohere Coral release and ARC Enterprise Benchmark data."
