# Amazon Nova Lite Model Card
# Following general model card template structure

model_name: Amazon Nova Lite
model_version: "1.0"
model_date: "2024-12"
model_type: Multimodal Large Language Model (Transformer-based)
model_description: |
  Amazon Nova Lite is a low-cost multimodal foundation model that is lightning fast for processing 
  images, video, documents and text. It accepts text, images, documents, and video as input and 
  generates text as output. Nova Lite is optimized for speed and cost-efficiency while maintaining 
  strong performance across multimodal understanding tasks, making it ideal for high-volume applications.

# Organization Information
developer: Amazon Artificial General Intelligence (AGI)
organization_name: Amazon
organization_contact: nova-technical-report@amazon.com
organization_website: https://aws.amazon.com/bedrock/nova/

# Model Characteristics
architecture: Transformer-based
parameters: Not listed in source
context_length: 300000  # 300k tokens
input_modalities:
  - text
  - image
  - document
  - video
output_modalities:
  - text
languages_supported:
  primary:
    - Arabic
    - Dutch
    - English
    - French
    - German
    - Hebrew
    - Hindi
    - Italian
    - Japanese
    - Korean
    - Portuguese
    - Russian
    - Chinese (Simplified)
    - Spanish
    - Turkish
  additional: Over 200 languages supported with varying degrees of proficiency
knowledge_cutoff: "2025-01"

# Intended Use
intended_use:
  primary_applications:
    - High-volume text and multimodal processing at low cost
    - Fast image, document, and video understanding
    - Real-time or near-real-time applications requiring quick responses
    - Cost-sensitive multimodal applications
    - Agentic workflows with fast function calling
    - Retrieval-augmented generation (RAG) for high-throughput scenarios
    - Document and chart analysis at scale
    - Video content analysis and captioning
    - Translation between 200+ language pairs
  
  intended_users:
    - Developers building cost-sensitive AI applications
    - Organizations requiring high-throughput multimodal processing
    - Startups and small businesses with budget constraints
    - Applications requiring fast response times
    - Data scientists prototyping multimodal applications
  
  use_case_examples:
    - Processing large volumes of documents for information extraction
    - Real-time chat applications with multimodal inputs
    - Batch processing of images or videos for content moderation
    - High-volume customer service applications
    - Fast web scraping and content analysis
    - Quick document summarization at scale

out_of_scope_use:
  prohibited_uses:
    - Generation of content intended to harm, deceive, or exploit individuals
    - Creation of information related to chemical, biological, radiological, or nuclear weapons
    - Generation of malicious code, malware, vulnerability exploits, or ransomware
    - Election-related manipulation or misinformation
    - Content that sexualizes, grooms, abuses, or otherwise harms minors
    - Unauthorized surveillance or privacy violations
    - Facilitating self-harm or suicide
    - Creating deepfakes or non-consensual intimate imagery
    - Generating hate speech or content promoting violent extremism
  
  limitations:
    - May not have information on events after January 2025 knowledge cutoff
    - Lower accuracy than Nova Pro on complex reasoning tasks
    - Cannot execute actions in the real world without integration with external tools
    - Not suitable as sole decision-maker for high-stakes domains without human oversight
    - May produce hallucinations or factually incorrect information
    - Performance varies across the 200+ supported languages
    - Optimized for speed over maximum accuracy on challenging tasks

# Training Data
training_data:
  data_sources:
    - Licensed commercial data
    - Proprietary Amazon data
    - Open source datasets
    - Publicly available data (where appropriate)
  
  data_composition:
    modalities:
      - text
      - images
      - documents
      - video
    languages: Over 200 languages with emphasis on 15 primary languages listed above
    domains: Not fully specified in source; includes general web data, code, documents, multimedia
  
  data_preprocessing:
    - Highly scalable filtering and deduplication pipelines
    - Data enrichment processes
    - De-identification or removal of certain types of personal data (when feasible)
    - Content filtering based on Responsible AI objectives
    - Pipelines built using AWS EMR and AWS Batch
  
  data_volume: Not listed in source
  data_collection_period: Not listed in source
  
  data_labeling:
    - Human preference data collected for RLHF
    - Single and multi-turn RAI demonstrations
    - Helpfulness/harmfulness studies
    - Instruction-demonstration pairs for supervised fine-tuning

# Training Procedure
training_procedure:
  training_stages:
    - stage: Pretraining
      description: |
        Training on mixture of large amounts of multilingual and multimodal data using 
        Transformer architecture
    
    - stage: Supervised Fine-Tuning (SFT)
      description: |
        Fine-tuning on instruction-demonstration pairs including multimodal examples, 
        single and multi-turn RAI demonstrations in multiple languages
    
    - stage: Reward Model Training
      description: |
        Training reward models from human preference data, including RAI-specific 
        reward models
    
    - stage: Alignment
      description: |
        Learning from human preferences via Direct Preference Optimization (DPO) and 
        Proximal Policy Optimization (PPO) to ensure alignment with human preferences 
        for quality and responsible behavior

  training_infrastructure:
    hardware:
      - Amazon Trainium1 (TRN1) custom chips
      - NVIDIA A100 GPUs (P4d instances)
      - NVIDIA H100 GPUs (P5 instances)
    networking: Petabit-scale non-blocking EFA network fabric
    orchestration: AWS SageMaker-managed Elastic Kubernetes Service (EKS) clusters
    storage:
      - AWS FSx for performant storage
      - AWS S3 for cost-efficient scaling
  
  training_optimizations:
    - Super-Selective Activation Checkpointing (SSC) - 50% memory reduction with 2% recomputation overhead
    - Optimized gradient reduction order and frequency for communication overlap
    - Enhanced PyTorch memory allocator to reduce stragglers
    - Fully distributed optimizer state and weight sharding
    - Asynchronous checkpoint loading with observer process
    - Cached and reused data indices
  
  training_performance:
    goodput: Up to 97% weekly average
    checkpoint_overhead: ~1 second on H100 clusters, ~0.1 second on TRN1 clusters
    mean_time_to_restart: 6.5 minutes average on TRN1 clusters
  
  training_duration: Not listed in source
  training_compute: Not listed in source

# Customization
customization:
  fine_tuning_supported: true
  fine_tuning_types:
    - Supervised fine-tuning on multimodal data
    - Model distillation from larger models (including Nova Pro)
    - Custom fine-tuning via Amazon Bedrock APIs
  fine_tuning_data_requirements: Multimodal data (text, images, documents, video)

# Performance
performance:
  evaluation_methodology: |
    Models evaluated on public benchmarks using standardized prompts and evaluation protocols. 
    95% confidence intervals calculated for binary score averages assuming Gaussian distribution. 
    Results include both cited public results and internal measurements via Bedrock API, OpenAI API, 
    and Gemini API.
  
  core_capabilities:
    language_understanding:
      - benchmark: MMLU
        score: 80.5
        unit: accuracy
        notes: 0-shot Chain-of-Thought, 57 subjects
      
      - benchmark: ARC-C
        score: 92.4
        confidence_interval: ±1.5
        unit: accuracy
        notes: 0-shot CoT, science QA grades 3-9
      
      - benchmark: DROP
        score: 80.2
        confidence_interval: ±0.8
        unit: F1-score
        notes: 0-shot CoT, discrete reasoning over paragraphs
    
    reasoning:
      - benchmark: GPQA
        score: 42.0
        confidence_interval: ±4.6
        unit: accuracy
        notes: 0-shot CoT, graduate-level questions
      
      - benchmark: BBH
        score: 82.4
        unit: accuracy
        notes: 3-shot CoT, 23 diverse reasoning tasks
    
    mathematics:
      - benchmark: MATH
        score: 73.3
        confidence_interval: ±1.2
        unit: accuracy
        notes: 0-shot CoT, competition-level problems
      
      - benchmark: GSM8K
        score: 94.5
        confidence_interval: ±1.2
        unit: accuracy
        notes: 0-shot CoT, grade school math
    
    instruction_following:
      - benchmark: IFEval
        score: 89.7
        confidence_interval: ±2.1
        unit: instruction-level accuracy (loose)
        notes: 0-shot, verifiable instruction following
    
    translation:
      - benchmark: FLORES (en→14 languages)
        scores:
          spBLEU: 41.5
          COMET22: 88.8
        notes: 0-shot translation to 14 languages
      
      - benchmark: FLORES (14 languages→en)
        scores:
          spBLEU: 43.1
          COMET22: 88.8
        notes: 0-shot translation from 14 languages
  
  multimodal_capabilities:
    image_understanding:
      - benchmark: MMMU
        score: 56.2
        confidence_interval: ±3.2
        unit: accuracy
        notes: Chain-of-Thought, college-level multimodal understanding
      
      - benchmark: ChartQA
        score: 86.8
        confidence_interval: ±1.3
        unit: relaxed accuracy
        notes: Chart question answering
      
      - benchmark: DocVQA
        score: 92.4
        unit: ANLS
        notes: Document visual question answering with OCR
      
      - benchmark: TextVQA
        score: 80.2
        unit: weighted accuracy
        notes: Text reading in natural images
    
    video_understanding:
      - benchmark: VATEX
        score: 77.8
        unit: CIDEr
        notes: Video captioning, ~10 second videos
      
      - benchmark: EgoSchema
        score: 71.4
        confidence_interval: ±5.4
        unit: accuracy
        notes: Long-form video QA with high certificate length
  
  agentic_performance:
    function_calling:
      - benchmark: BFCL Overall
        score: 66.6
        unit: accuracy
        notes: Berkeley Function Calling Leaderboard v3
      
      - benchmark: BFCL AST
        score: 87.5
        unit: accuracy
        notes: Abstract Syntax Tree match
      
      - benchmark: BFCL Execution
        score: 86.4
        unit: accuracy
        notes: Function execution correctness
      
      - benchmark: BFCL Relevance
        score: 97.6
        unit: accuracy
        notes: Appropriate function selection
      
      - benchmark: BFCL Irrelevance
        score: 49.1
        unit: accuracy
        notes: Recognizing when no function applies
    
    multimodal_agents:
      - benchmark: VisualWebBench
        score: 77.7
        unit: composite score
        notes: 7 web browsing tasks across 100+ websites
      
      - benchmark: MM-Mind2Web
        score: 60.7
        unit: step accuracy
        notes: Multimodal web navigation
      
      - benchmark: GroundUI-1K
        score: 80.2
        unit: accuracy
        notes: UI element grounding
  
  long_context:
    - benchmark: Text Needle-in-Haystack
      score: ">95%"
      unit: recall
      notes: Up to 300k tokens, various depths and positions
    
    - benchmark: SQuALITY
      score: 19.2
      confidence_interval: ±8.6
      unit: ROUGE-L
      notes: Query-based summarization of literary stories
    
    - benchmark: LVBench
      score: 40.4
      confidence_interval: ±2.4
      unit: accuracy
      notes: Long video understanding (99 videos, 1549 questions)
  
  functional_expertise:
    software_engineering:
      - benchmark: HumanEval Python
        score: 85.4
        confidence_interval: ±5.4
        unit: pass@1
        notes: 0-shot code generation
    
    financial_analysis:
      - benchmark: FinQA
        score: 73.6
        confidence_interval: ±0.9
        unit: accuracy
        notes: 0-shot CoT, financial reasoning
    
    retrieval_augmented_generation:
      - benchmark: CRAG
        score: 43.8
        confidence_interval: ±1.9
        unit: accuracy
        notes: Comprehensive RAG benchmark
  
  runtime_performance:
    - metric: Time to First Token
      value: 0.6
      unit: seconds
      notes: 1000 input tokens, 100 output tokens (fastest in class)
    
    - metric: Output Tokens per Second
      value: 157
      unit: tokens/second
      notes: Generation throughput (fastest in intelligence tier)
    
    - metric: Total Response Time
      value: 1.1
      unit: seconds
      notes: 1000 input tokens, 100 output tokens

# Limitations and Biases
limitations:
  technical_limitations:
    - Knowledge cutoff of January 2025 - may not have information on more recent events
    - Context window limited to 300k tokens
    - May produce hallucinations or factually incorrect information
    - Performance varies significantly across the 200+ supported languages
    - Lower accuracy than Nova Pro on complex reasoning and graduate-level tasks
    - Video understanding limited to visual and temporal information (no audio processing mentioned)
    - Cannot execute real-world actions without integration with external tools/APIs
    - Optimized for speed and cost, which may result in reduced accuracy on challenging tasks
  
  domain_limitations:
    - Not suitable as sole decision-maker in high-stakes domains without human oversight
    - May struggle with highly specialized technical or scientific domains
    - Financial analysis should not replace professional financial advice
    - Legal reasoning should not replace qualified legal counsel
    - Medical information should not replace professional medical advice
    - Less suitable for tasks requiring maximum accuracy over speed
  
  known_failure_modes:
    - May fail to recognize when it lacks sufficient information to answer
    - Can be influenced by adversarial prompts despite alignment efforts
    - May exhibit bias toward more common languages in training data
    - Long-form generation may lose coherence or drift from original topic
    - May have difficulty with tasks requiring real-time or constantly updating information
    - May produce lower quality outputs on complex multi-step reasoning compared to Nova Pro

biases:
  bias_evaluation:
    approach: |
      Evaluated using public benchmarks (BOLD, RealToxicityPrompts, MM-SafetyBench) and proprietary 
      dynamically updating benchmarks across Responsible AI dimensions. Multi-pronged evaluation 
      including internal red teaming, external expert red teaming, and automated red teaming.
    
    benchmarks_used:
      - BOLD (biases in open-ended language generation)
      - RealToxicityPrompts
      - MM-SafetyBench
      - Proprietary RAI benchmarks across 8 dimensions
  
  identified_biases:
    - Performance varies across languages, with better performance on emphasized languages
    - May reflect biases present in training data sources
    - Potential Western-centric bias given data composition (inference based on typical web data)
    - Evaluation results not fully disclosed in source
  
  mitigation_strategies:
    - Extensive RAI alignment during SFT and RLHF stages
    - RAI-specific reward models
    - Input and output moderation models as first and last line of defense
    - Multi-turn RAI demonstrations in multiple languages
    - Helpfulness/harmfulness studies to balance safety and utility
    - Regular red teaming exercises (300+ distinct attack techniques)
    - Continuous dataset updates based on red teaming findings

# Responsible AI
responsible_ai:
  framework:
    dimensions:
      - name: Fairness
        definition: Considering impacts on different groups of stakeholders
        approach: |
          RAI demonstrations, human preference data collection, and evaluation across 
          demographic dimensions. Not storing or reinforcing unsafe preferences.
      
      - name: Explainability
        definition: Understanding and evaluating system outputs
        approach: |
          Leverage explainable AI methods throughout development. Services like Amazon 
          SageMaker Clarify enable downstream developers to explain predictions.
      
      - name: Privacy and Security
        definition: Appropriately obtaining, using, and protecting data and models
        approach: |
          Data access controls, de-identification of personal data when feasible, 
          red teaming for data privacy, model output alignment.
      
      - name: Safety
        definition: Preventing harmful system output and misuse
        approach: |
          Multi-stage alignment, input/output moderation, extensive red teaming across 
          prohibited use cases, reward models focused on safety.
      
      - name: Controllability
        definition: Having mechanisms to monitor and steer AI system behavior
        approach: |
          Partnership with Model Evaluation and Threat Research (METR) center, 
          evaluation against risks like sensitive data exfiltration and unauthorized actions.
      
      - name: Veracity and Robustness
        definition: Achieving correct system outputs, even with unexpected or adversarial inputs
        approach: |
          Adversarial testing including prompt injection, jailbreaking, obfuscation 
          techniques. Over 300 distinct attack techniques tested.
      
      - name: Governance
        definition: Incorporating best practices into the AI supply chain
        approach: |
          Working-backwards product process with RAI at design phase, design consultations, 
          implementation assessments, routine testing, customer reviews.
      
      - name: Transparency
        definition: Enabling stakeholders to make informed choices
        approach: |
          This model card, technical documentation, commitment to transparency in 
          development and deployment practices.
  
  red_teaming:
    internal:
      - Trained data analysts and subject-matter experts
      - Over 300 distinct attack techniques across multiple languages and modalities
      - Techniques include prompt injection, jailbreaking, obfuscation, multilingual attacks
      - Cross-modality attacks embedding adversarial content in visual inputs
      - Iterative feedback loop for model improvement
    
    external_partners:
      - partner: ActiveFence
        focus: Hate speech, political misinformation, extremism
        methodology: 9700+ adversarial prompts across 20 categories
      
      - partner: Deloitte Consulting
        focus: Biological weapons risks (CBRN)
        methodology: 30-question panel testing scientific knowledge and reasoning for biological risks
      
      - partner: Gomes Group (Carnegie Mellon University)
        focus: Chemical weapons risks (CBRN)
        methodology: Automated and non-automated evaluations on hazardous chemicals
      
      - partner: Nemesys Insights LLC
        focus: Radiological and Nuclear risks (CBRN)
        methodology: Uplift studies and scenario-based red teaming with 8 subject matter experts
    
    automated:
      framework: FLIRT (Feedback Loop In-context Red Teaming)
      approach: |
        Uses seed prompts identified by human evaluators, generates additional prompts via 
        in-context learning, evaluates responses, extracts successful attacks for next iteration. 
        Covers multi-turn interactions, multiple languages, and multiple modalities.
  
  commitments:
    - US White House voluntary commitments on safe, secure, transparent AI development
    - G7 AI Hiroshima Process Code of Conduct
    - Participation in AI Safety Summits (UK and Seoul)
    - Frontier Model Forum membership
    - Partnership on AI membership
    - Engagement with NIST and other government forums
  
  runtime_mitigations:
    input_moderation: Detects malicious, insecure, illegal content and bypass attempts
    output_moderation: Ensures content adheres to RAI objectives
    approach: First and last line of defense allowing rapid response to new threats

# Ethical Considerations
ethical_considerations:
  dual_use: |
    Model has potential for both beneficial and harmful applications. Mitigated through 
    alignment training, moderation systems, and usage policies prohibiting harmful applications.
  
  environmental_impact: Not listed in source
  
  labor_practices: |
    Uses third-party vendors for human evaluation and red teaming with rigorous quality 
    standards and spot-checking processes.
  
  data_privacy: |
    De-identification or removal of certain types of personal data from training when feasible. 
    Red teaming includes data privacy assessments.

# Licensing and Access
license: Not listed in source
access:
  availability: Available via Amazon Bedrock
  api_access: Yes, through Amazon Bedrock APIs
  restrictions: Subject to Amazon Bedrock terms of service and acceptable use policies
  pricing: Not listed in source (described as low-cost with industry-leading price performance)

# Model Card Contact
model_card_authors:
  - Amazon Artificial General Intelligence (AGI) Team
model_card_contact: nova-technical-report@amazon.com
model_card_version: "1.0"
model_card_date: "2024-12"

# Citation
citation: |
  @misc{novatechreport,
    author = {Amazon AGI},
    title = {The Amazon Nova Family of Models: Technical Report and Model Card},
    year = {2024},
    url = {https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card}
  }

# Additional Resources
additional_resources:
  technical_report: https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card
  documentation: https://docs.aws.amazon.com/nova/latest/userguide
  huggingface_materials: https://huggingface.co/amazon-agi
  bedrock_console: https://aws.amazon.com/bedrock/nova/
