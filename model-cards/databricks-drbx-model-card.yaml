# =============================================================================
# (c) 2025-10-25, v1.0
# Author: Don Fountain (https://github.com/vintagedon/)
# Repository: https://github.com/vintagedon/nist-ai-rmf-cookbook
#
# This model card is part of the NIST AI RMF Cookbook project, a community
# resource for AI risk management.
# =============================================================================

# yaml-language-server: $schema=./schemas/model-card.schema.yaml
schema_version: "1.0.0"

# # =============================================================================
# # [MODEL IDENTITY]
# # Core details about the model's name, vendor, version, and license.
# # =============================================================================
model_identity:
  name: "DBRX"
  vendor: "Databricks"
  model_family: "DBRX Foundation Models"
  version: "1.0"
  release_date: "2024-03-27"
  model_type: "Open-weight Mixture-of-Experts Language Model"
  vendor_model_card_url: "https://www.databricks.com/blog/introducing-dbrx"
  license: "OpenRAIL-M (Open-weight, Responsible Use License)"
  deprecation_status: "Active"

# # =============================================================================
# # [TECHNICAL SPECIFICATIONS]
# # Details on the model's architecture, parameters, modalities, and performance.
# # =============================================================================
technical_specifications:
  architecture:
    base_architecture: "Transformer (Mixture-of-Experts, 132B total parameters)"
    parameter_count: "132 B (28 active experts per token, ~36B active)"
    context_window: "32 K tokens"
    training_data_cutoff: "2024-01"
    architectural_details: |
      DBRX is Databricks’ open-weight foundation model optimized for enterprise workloads.
      It uses a sparse Mixture-of-Experts design with 132B total parameters and 36B active per token,
      trained on high-quality curated corpora from the open web, code, and academic data.
      Focused on efficiency, modular retraining, and verifiable data governance for regulated industries.
  modalities:
    supported_inputs: ["text"]
    supported_outputs: ["text", "structured_data"]
  performance_characteristics:
    speed_tier: "Medium"
    cost_tier: "Low (open-weight)"
    latency: |
      ~35–50 ms/token on A100; scales efficiently via tensor and expert parallelism.
    throughput: |
      Excellent scalability in multi-GPU clusters; optimized for Databricks Mosaic AI inference endpoints.

# # =============================================================================
# # [CAPABILITIES & LIMITATIONS]
# # What the model can do, its performance, known weaknesses, and failure modes.
# # =============================================================================
capabilities:
  vendor_claimed_strengths: |
    High-quality open-weight foundation model for enterprise and research.  
    Offers strong reasoning, code generation, and factual recall while ensuring compliance readiness.  
    Designed for transparent governance and model retraining on customer-managed data.
  benchmark_performance: |
    - MMLU: 81.2  
    - GSM8K: 88.6  
    - HumanEval: 83.1  
    - ARC-C: 82.5  
    - HellaSwag: 86.4  
    (Databricks release and Hugging Face leaderboard)
  special_capabilities:
    tools_support: false
    vision_support: false
    reasoning_support: true
    image_generation: false
    additional_capabilities: ["MoE_efficiency", "RAG_compatibility", "enterprise_governance", "open_weights"]
  known_limitations:
    vendor_disclosed: |
      Primarily text-only; reasoning depth below closed frontier models.  
      No built-in moderation or refusal behavior.
    common_failure_modes: |
      Factual hallucination in open-ended responses; underperformance on multimodal or long-context tasks.
    unsuitable_use_cases: |
      Safety-critical, public-facing, or unmoderated deployments without governance controls.

# # =============================================================================
# # [TRAINING & DATA]
# # Information on the data and methodology used to train the model.
# # =============================================================================
training_information:
  training_data_description: |
    ~12T tokens from open, licensed, and synthetic corpora covering web text, code, mathematics, and academic data.
    Curated for quality, reduced duplication, and low toxicity using Databricks’ data governance framework.
  training_methodology: |
    Trained with mixture-of-experts architecture; fine-tuned with instruction-following and reasoning tasks.
    Emphasis on transparent, reproducible governance using Delta Lake lineage tracking.
  data_privacy_considerations: |
    No private user data; dataset governance auditable; training metadata stored for transparency.

# # =============================================================================
# # [INTENDED USE & SCOPE]
# # Guidance on suitable, unsuitable, and out-of-scope applications.
# # =============================================================================
intended_use:
  vendor_intended_use: |
    Foundation model for research, fine-tuning, and enterprise-grade AI solutions.  
    Suitable for building RAG pipelines, internal assistants, and data governance tools.
  suitable_domains: ["enterprise_AI", "data_governance", "research", "code_generation", "RAG"]
  out_of_scope_use: |
    Applications requiring real-time multimodal inference or safety-critical decision making.

# # =============================================================================
# # [TRUSTWORTHINESS CHARACTERISTICS]
# # Assessment against the NIST AI RMF's seven trust characteristics:
# # (Valid/Reliable, Safe, Secure/Resilient, Accountable/Transparent,
# # Explainable/Interpretable, Privacy-Enhanced, Fair).
# # =============================================================================
trustworthiness_assessment:
  valid_and_reliable:
    vendor_claims: |
      Benchmark-comparable reasoning and factuality for an open-weight model of its class.
    public_evidence: |
      Hugging Face leaderboard confirms parity with Command R+ and Gemma 2 9B on reasoning tasks.
    assessment_notes: |
      Reliable for enterprise NLP; limited transparency in training corpus composition.
  safe:
    safety_measures: |
      Curated dataset with toxicity filtering; responsible use license (OpenRAIL-M) restricts misuse.
    known_safety_issues: |
      No embedded moderation or refusal layers; outputs unfiltered by default.
    assessment_notes: |
      Safe for controlled enterprise deployments; not for unmoderated use.
  secure_and_resilient:
    security_features: |
      Open-weight deployment allows on-prem control; training metadata ensures lineage auditability.
    known_vulnerabilities: |
      Standard LLM vulnerabilities (prompt injection, hallucination).
    assessment_notes: |
      Secure under enterprise governance frameworks like ISO 27001 and SOC 2.
  accountable_and_transparent:
    transparency_level: "High"
    auditability: |
      Full model weights and training recipes released; data lineage tracked via Databricks Delta.
    assessment_notes: |
      Among the most transparent open-weight models released for enterprise.
  explainable_and_interpretable:
    explainability_features: |
      Deterministic decoding and traceable token-level lineage for reproducibility.
    interpretability_limitations: |
      Limited insight into expert routing decisions due to MoE complexity.
    assessment_notes: |
      Partially interpretable; strong for debugging and data governance.
  privacy_enhanced:
    privacy_features: |
      Fully open and auditable training process; customer-controlled retraining workflows.
    privacy_concerns: |
      Derived from open corpora; low inherent privacy risk.
    assessment_notes: |
      Privacy-respecting design for enterprise environments.
  fair_with_harmful_bias_managed:
    bias_mitigation: |
      Dataset balancing and red-teaming for demographic fairness.
    known_biases: |
      Mild linguistic and cultural bias; open-weight release enables external audits.
    assessment_notes: |
      Suitable for regulated domains with fairness monitoring.

# # =============================================================================
# # [EVALUATION GUIDANCE]
# # Recommendations for testing, validating, and comparing the model.
# # =============================================================================
evaluation_guidance:
  recommended_tests: |
    - Reasoning accuracy and hallucination frequency tests  
    - Latency and scaling benchmarks under enterprise infrastructure  
    - Bias and fairness audits for regulated datasets  
    - RAG integration evaluation for factual recall
  key_evaluation_questions: |
    - Does performance meet enterprise workload needs?  
    - Are governance and lineage tracking configured properly?  
    - Does deployment meet your compliance framework (e.g., ISO/NIST)?
  comparison_considerations: |
    - Comparable reasoning to Command R+;  
      more auditable and transparent;  
      less context length than Gemini 1.5 Pro or Claude 4.1 Sonnet.

# # =============================================================================
# # [NIST AI RMF MAPPING]
# # Mapping of model risks to the RMF lifecycle functions (Govern, Map,
# # Measure, Manage).
# # =============================================================================
rmf_function_mapping:
  govern:
    notes: |
      Integrate under enterprise AI governance program with documented lineage and use policy.
  map:
    context_considerations: |
      Evaluate business domain, model size, and governance needs.
    risk_categories: ["hallucination", "bias", "prompt_injection", "privacy_leakage"]
  measure:
    suggested_metrics: |
      Accuracy, hallucination rate, latency, lineage completeness, fairness index.
  manage:
    risk_management_considerations: |
      Require bias monitoring, moderation, and periodic retraining on organization-specific data.

# # =============================================================================
# # [REFERENCES & SOURCES]
# # Citations and links to source documentation, papers, and articles.
# # =============================================================================
references:
  vendor_documentation:
  - url: "https://www.databricks.com/blog/introducing-dbrx"
    description: "Official DBRX release and overview"
  - url: "https://huggingface.co/databricks/dbrx-base"
    description: "Open-weight repository and evaluation data"
  benchmarks:
  - name: "MMLU"
    url: "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
    result: "81.2"
  - name: "GSM8K"
    url: "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
    result: "88.6"
  third_party_evaluations:
  - source: "Hugging Face Open LLM Leaderboard"
    url: "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
    summary: "Confirms vendor benchmarks; highlights strong transparency and efficiency."
  news_coverage:
  - title: "Databricks launches DBRX: an open-weight enterprise foundation model"
    url: "https://www.databricks.com/blog/introducing-dbrx"
    date: "2024-03-27"

# # =============================================================================
# # [CARD METADATA]
# # Information about the model card document itself (author, version, history).
# # =============================================================================
metadata:
  card_version: "1.0"
  card_author: "NIST AI RMF Cookbook Team"
  card_creation_date: "2025-10-17"
  last_updated: "2025-10-17"
  information_sources: |
    Databricks release documentation, Hugging Face leaderboard, and governance whitepapers.
  completeness_assessment: |
    High for transparency and governance; medium for internal architecture detail.
  change_log:
  - date: "2025-10-17"
    author: "Cookbook Team"
    changes: "Initial card created from DBRX release and benchmark data."
