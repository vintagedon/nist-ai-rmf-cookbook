schema_version: Not Listed in Source
model_identity:
  name: Claude 3 Haiku
  vendor: Anthropic
  model_family: Claude 3
  version: Not Listed in Source
  release_date: Not Listed in Source
  model_type: Not Listed in Source
  vendor_model_card_url: Not Listed in Source
  license: Not Listed in Source
  deprecation_status: Not Listed in Source
technical_specifications:
  architecture:
    base_architecture: Not Listed in Source
    parameter_count: Not Listed in Source
    context_window: Not Listed in Source
    training_data_cutoff: Not Listed in Source
    architectural_details: Described as a large multimodal model; supports image +
      text inputs.
  modalities:
    supported_inputs:
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    supported_outputs:
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
    input_types:
    - text
  performance_characteristics:
    speed_tier: Not Listed in Source
    cost_tier: Not Listed in Source
    latency: Not Listed in Source
    throughput: Not Listed in Source
    latency_profile: Fastest in Claude 3 family (qualitative, per PDF).
    cost_tiers: Least expensive in Claude 3 family (qualitative, per PDF).
capabilities:
  vendor_claimed_strengths:
  - Fastest and least expensive model in the Claude 3 family.
  - Performs as well or better than Claude 2 on most pure-text tasks.
  benchmark_performance:
  - 'AI2D (0-shot, T=0): 80.6%'
  - Report discusses benchmarks including GPQA, MMLU, and MMMU (SOTA claims for Opus).
  special_capabilities: Vision-enabled (image understanding) per report.
  known_limitations: Lower capability than Sonnet/Opus per report; Sonnet and Opus
    significantly outperform Haiku.
training_information:
  training_data_description: Not Listed in Source
  training_methodology: Not Listed in Source
  data_privacy_considerations: Not Listed in Source
intended_use:
  vendor_intended_use: Not Listed in Source
  suitable_domains:
  - Not Listed in Source
  - Not Listed in Source
  - Not Listed in Source
  out_of_scope_use: Not Listed in Source
trustworthiness_assessment:
  valid_and_reliable:
    vendor_claims: Not Listed in Source
    public_evidence: Not Listed in Source
    assessment_notes: Not Listed in Source
  safe: Includes analysis of safety and societal impacts and catastrophic risk assessments
    per Anthropic Responsible Scaling Policy.
  secure_and_resilient:
    security_features: Not Listed in Source
    known_vulnerabilities: Not Listed in Source
    assessment_notes: Not Listed in Source
  accountable_and_transparent:
    transparency_level: Not Listed in Source
    auditability: Not Listed in Source
    assessment_notes: Not Listed in Source
  explainable_and_interpretable:
    explainability_features: Not Listed in Source
    interpretability_limitations: Not Listed in Source
    assessment_notes: Not Listed in Source
  privacy_enhanced:
    privacy_features: Not Listed in Source
    privacy_concerns: Not Listed in Source
    assessment_notes: Not Listed in Source
  fair_with_harmful_bias_managed:
    bias_mitigation: Not Listed in Source
    known_biases: Not Listed in Source
    assessment_notes: Not Listed in Source
evaluation_guidance:
  recommended_tests: Not Listed in Source
  key_evaluation_questions: Validate performance on your domain tasks; compare latency/cost
    vs capability across Opus/Sonnet/Haiku.
  comparison_considerations: Haiku optimizes speed and cost; Sonnet and Opus provide
    higher capability; verify vision performance on your image types.
rmf_function_mapping:
  govern:
    notes: Not Listed in Source
  map:
    context_considerations: Not Listed in Source
    risk_categories:
    - Not Listed in Source
    - Not Listed in Source
    - Not Listed in Source
  measure:
    suggested_metrics: Not Listed in Source
  manage:
    risk_management_considerations: Not Listed in Source
references:
  vendor_documentation:
  - 'Local file: Claude 3 Model Card.pdf'
  benchmarks:
  - AI2D
  - GPQA
  - MMLU
  - MMMU
  third_party_evaluations:
  - source: Not Listed in Source
    url: Not Listed in Source
    summary: Not Listed in Source
metadata:
  card_version: 0.3-haiku-from-pdf
  card_author: Governance Assistant
  card_creation_date: '2025-10-28'
  last_updated: Not Listed in Source
  information_sources:
  - 'Local file: Claude 3 Model Card.pdf'
  completeness_assessment: Populated with statements explicitly present in the PDF;
    numeric results only included where directly stated (e.g., AI2D).
  change_log:
  - date: '2025-10-28'
    author: Governance Assistant
    changes: Rebuilt card to align with template and include AI2D benchmark.
  review_cycle: Quarterly
