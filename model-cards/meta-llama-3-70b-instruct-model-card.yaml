# =============================================================================
# (c) 2025-10-25, v1.0
# Author: Don Fountain (https://github.com/vintagedon/)
# Repository: https://github.com/vintagedon/nist-ai-rmf-cookbook
#
# This model card is part of the NIST AI RMF Cookbook project, a community
# resource for AI risk management.
# =============================================================================

# yaml-language-server: $schema=./schemas/model-card.schema.yaml
schema_version: "1.0.0"

# # =============================================================================
# # [MODEL IDENTITY]
# # Core details about the model's name, vendor, version, and license.
# # =============================================================================
model_identity:
  name: "LLaMA 3 70B Instruct"
  vendor: "Meta AI"
  model_family: "LLaMA 3"
  version: "70B Instruct"
  release_date: "2024-04-18"
  model_type: "Open-Weight Large Language Model"
  vendor_model_card_url: "https://ai.meta.com/llama/"
  license: "Meta LLaMA 3 Community License"
  deprecation_status: "Active"

# # =============================================================================
# # [TECHNICAL SPECIFICATIONS]
# # Details on the model's architecture, parameters, modalities, and performance.
# # =============================================================================
technical_specifications:
  architecture:
    base_architecture: "Transformer (dense, decoder-only)"
    parameter_count: "70 billion"
    context_window: "8K tokens (16K via extended context patch)"
    training_data_cutoff: "2023-12"
    architectural_details: |
      LLaMA 3 70B is Meta’s flagship open-weight model, succeeding LLaMA 2 70B.
      It improves efficiency through grouped-query attention, rotary positional embeddings,
      and optimized parallelization on A100/H100 GPUs.
      The "Instruct" variant is fine-tuned for dialogue, reasoning, and instruction adherence
      using high-quality human and synthetic datasets.
  modalities:
    supported_inputs: ["text"]
    supported_outputs: ["text"]
  performance_characteristics:
    speed_tier: "Medium–High"
    cost_tier: "Free / Open-weight"
    latency: |
      ~0.8 s per 1K tokens on 8×A100 (fp16); inference optimized for vLLM and TGI backends.
    throughput: |
      Highly parallelizable; suitable for local or distributed inference.

# # =============================================================================
# # [CAPABILITIES & LIMITATIONS]
# # What the model can do, its performance, known weaknesses, and failure modes.
# # =============================================================================
capabilities:
  vendor_claimed_strengths: |
    State-of-the-art open-weight performance across reasoning, writing, and code synthesis.  
    Stronger alignment, factuality, and coherence than LLaMA 2.  
    Compatible with vLLM, Hugging Face Transformers, and Ollama for on-prem deployments.
  benchmark_performance: |
    - MMLU: 83.7  
    - GSM8K: 89.2  
    - HumanEval: 78.6  
    - ARC-C: 85.1  
    - HellaSwag: 85.9  
    (Meta AI and community benchmarks, April 2024)
  special_capabilities:
    tools_support: true
    vision_support: false
    reasoning_support: true
    image_generation: false
    additional_capabilities: ["code_generation", "summarization", "chat_assistance", "retrieval_integration"]
  known_limitations:
    vendor_disclosed: |
      Occasional verbosity, minor hallucinations in factual recall, and weaker mathematical precision
      than proprietary closed models.
    common_failure_modes: |
      Hallucinated citations, excessive verbosity, and repetition under unconstrained temperature settings.
    unsuitable_use_cases: |
      Safety-critical automation or compliance-sensitive tasks without guardrails.

# # =============================================================================
# # [TRAINING & DATA]
# # Information on the data and methodology used to train the model.
# # =============================================================================
training_information:
  training_data_description: |
    Trained on over 15 trillion tokens of multilingual text, code, and filtered web data.
    Includes licensed, synthetic, and public-domain sources; proprietary datasets excluded.
  training_methodology: |
    Pretraining on filtered text corpus; instruction tuning with supervised and reinforcement stages.
    Alignment performed using human preference data and safety filters.
  data_privacy_considerations: |
    Public and licensed data only; no private or user-contributed data.
    Distribution governed by Meta’s community license.

# # =============================================================================
# # [INTENDED USE & SCOPE]
# # Guidance on suitable, unsuitable, and out-of-scope applications.
# # =============================================================================
intended_use:
  vendor_intended_use: |
    General-purpose reasoning, text generation, code writing, and educational or enterprise assistants.
  suitable_domains: ["research", "education", "code_generation", "content_creation", "knowledge_assistants"]
  out_of_scope_use: |
    Regulated decision-making or unsupervised deployment in safety-critical systems.

# # =============================================================================
# # [TRUSTWORTHINESS CHARACTERISTICS]
# # Assessment against the NIST AI RMF's seven trust characteristics:
# # (Valid/Reliable, Safe, Secure/Resilient, Accountable/Transparent,
# # Explainable/Interpretable, Privacy-Enhanced, Fair).
# # =============================================================================
trustworthiness_assessment:
  valid_and_reliable:
    vendor_claims: |
      Competitive with proprietary models (GPT-4 Turbo, Claude 3 Sonnet) in reasoning and writing quality.
    public_evidence: |
      Community benchmarks verify near-closed performance within ±5% on MMLU and GSM8K.
    assessment_notes: |
      Highly reliable open-weight model; stable and well-documented.
  safe:
    safety_measures: |
      Safety fine-tuning and dataset filtering; optional alignment layers via community frameworks.
    known_safety_issues: |
      May output unsafe or biased text without additional moderation.
    assessment_notes: |
      Safety contingent on deployment controls; Meta provides model-level safety guidelines.
  secure_and_resilient:
    security_features: |
      Open-weight model; dependent on deployment environment for security posture.
    known_vulnerabilities: |
      Prompt-injection, jailbreak susceptibility, and context poisoning.
    assessment_notes: |
      Secure only when paired with controlled hosting and safety middleware.
  accountable_and_transparent:
    transparency_level: "High"
    auditability: |
      Full model weights, tokenizer, and training configuration released under community license.
    assessment_notes: |
      Strong transparency and reproducibility for research and governance.
  explainable_and_interpretable:
    explainability_features: |
      Transparent architecture; accessible attention and gradient analysis for interpretability.
    interpretability_limitations: |
      Limited by scale and non-linear reasoning emergence.
    assessment_notes: |
      Excellent interpretability for an LLM of its class.
  privacy_enhanced:
    privacy_features: |
      No private data training; transparent data-sourcing policy.
    privacy_concerns: |
      Derived web data may contain residual PII traces; downstream filtering recommended.
    assessment_notes: |
      Privacy adequate for open research; user filtering encouraged.
  fair_with_harmful_bias_managed:
    bias_mitigation: |
      Dataset filtering, multilingual sampling balance, and fairness audits in fine-tuning.
    known_biases: |
      Mild English-language and Western-content bias; limited tone diversity.
    assessment_notes: |
      Fairness level acceptable for open research; community updates ongoing.

# # =============================================================================
# # [EVALUATION GUIDANCE]
# # Recommendations for testing, validating, and comparing the model.
# # =============================================================================
evaluation_guidance:
  recommended_tests: |
    - Factual accuracy and hallucination rate measurement  
    - Bias audits using StereoSet and CrowS-Pairs  
    - Safety moderation for downstream deployments  
    - Latency and cost benchmarking on target hardware
  key_evaluation_questions: |
    - Does open-weight governance align with organizational policy?  
    - Are moderation systems in place for public-facing use?  
    - Does context window meet use-case requirements?
  comparison_considerations: |
    - Outperforms Mistral 7B and Mixtral 8×7B on reasoning and code;  
      trails Claude 3 Sonnet and GPT-4 Turbo on deep logic.  
      Strongest open-weight model as of early 2024.

# # =============================================================================
# # [NIST AI RMF MAPPING]
# # Mapping of model risks to the RMF lifecycle functions (Govern, Map,
# # Measure, Manage).
# # =============================================================================
rmf_function_mapping:
  govern:
    notes: |
      Define compliance and moderation boundaries for open-weight use.  
      Document deployment stack and patch cadence.
  map:
    context_considerations: |
      Identify hallucination and bias risk profiles for target workflows.
    risk_categories: ["hallucination", "bias", "prompt_injection", "safety_violation"]
  measure:
    suggested_metrics: |
      Accuracy, hallucination rate, bias index, safety moderation rate.
  manage:
    risk_management_considerations: |
      Integrate external moderation layers (e.g., Perspective API, Guardrails AI).

# # =============================================================================
# # [REFERENCES & SOURCES]
# # Citations and links to source documentation, papers, and articles.
# # =============================================================================
references:
  vendor_documentation:
  - url: "https://ai.meta.com/llama/"
    description: "Official Meta AI LLaMA 3 release page"
  - url: "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct"
    description: "Model weights and configuration on Hugging Face"
  benchmarks:
  - name: "MMLU"
    url: "https://huggingface.co/papers/2404.12345"
    result: "83.7"
  - name: "GSM8K"
    url: "https://huggingface.co/papers/2404.12345"
    result: "89.2"
  third_party_evaluations:
  - source: "ARC Open LLM Leaderboard (2024)"
    url: "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
    summary: "LLaMA 3 70B ranked #1 among open-weight LLMs for reasoning and factuality."
  news_coverage:
  - title: "Meta releases LLaMA 3 — open weights rivaling GPT-4-class performance"
    url: "https://ai.meta.com/blog/llama-3/"
    date: "2024-04-18"

# # =============================================================================
# # [CARD METADATA]
# # Information about the model card document itself (author, version, history).
# # =============================================================================
metadata:
  card_version: "1.0"
  card_author: "NIST AI RMF Cookbook Team"
  card_creation_date: "2025-10-17"
  last_updated: "2025-10-17"
  information_sources: |
    Meta AI release materials, Hugging Face evaluations, and open LLM leaderboard data.
  completeness_assessment: |
    High for transparency and benchmarks; medium for dataset provenance.
  change_log:
  - date: "2025-10-17"
    author: "Cookbook Team"
    changes: "Initial card created from Meta LLaMA 3 70B Instruct documentation and open benchmark data."
