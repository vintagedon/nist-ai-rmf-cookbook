# Model Exit Interview Template
## AI RMF Compliance Review

**Template Version:** 1.0.0  
**Purpose:** Structured evaluation of repository artifacts (policies, schemas, documentation, research) against NIST AI RMF alignment

---

## Review Metadata

| Field | Value |
|-------|-------|
| **Artifact Reviewed** | [Name and path of artifact being evaluated] |
| **Artifact Type** | [Policy / Schema / Documentation / Research / Example] |
| **Reviewing Model** | [Model name and version, e.g., Claude Sonnet 4.5, GPT-4o] |
| **Review Date** | [YYYY-MM-DD] |
| **Reviewer Role** | [Primary Author / Secondary Validation / Independent Review] |
| **Review Scope** | [Full Review / Targeted Assessment / Quick Validation] |

---

## Executive Summary

**Overall RMF Alignment Score:** [0-100]

**Key Strengths:**
- [Strength 1]
- [Strength 2]
- [Strength 3]

**Critical Gaps:**
- [Gap 1]
- [Gap 2]
- [Gap 3]

**Recommendation:** [Approve / Approve with Minor Revisions / Major Revisions Required / Reject]

---

## RMF Function Analysis

### 1. GOVERN - Culture and Oversight

**Definition:** Cultivates organizational culture and establishes oversight structures for AI risk management.

**Evaluation Criteria:**
- Does artifact establish or support governance structures?
- Are roles and responsibilities clearly defined?
- Is accountability framework present?
- Does it support organizational AI risk tolerance definition?

**Findings:**

| Aspect | Score (0-25) | Evidence | Notes |
|--------|--------------|----------|-------|
| Governance Structure | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Role Definition | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Accountability | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Risk Tolerance | [0-25] | [Quote/reference from artifact] | [Assessment] |

**Function Score:** [0-100] (Average of aspects)

**Strengths:**
- [Specific strength with evidence]

**Gaps:**
- [Specific gap with recommendation]

---

### 2. MAP - Context and Risk Identification

**Definition:** Identifies and understands AI-specific risks in organizational context.

**Evaluation Criteria:**
- Does artifact identify AI-specific risks?
- Is context appropriately considered?
- Are stakeholders and impacts identified?
- Does it support risk categorization or taxonomy?

**Findings:**

| Aspect | Score (0-25) | Evidence | Notes |
|--------|--------------|----------|-------|
| Risk Identification | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Context Analysis | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Stakeholder Impact | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Risk Categorization | [0-25] | [Quote/reference from artifact] | [Assessment] |

**Function Score:** [0-100] (Average of aspects)

**Strengths:**
- [Specific strength with evidence]

**Gaps:**
- [Specific gap with recommendation]

---

### 3. MEASURE - Testing and Evaluation

**Definition:** Tests, evaluates, and quantifies AI system performance and risk controls.

**Evaluation Criteria:**
- Does artifact define or support measurement approaches?
- Are metrics specified or measurable outcomes defined?
- Is evaluation methodology clear?
- Does it enable continuous monitoring?

**Findings:**

| Aspect | Score (0-25) | Evidence | Notes |
|--------|--------------|----------|-------|
| Measurement Approach | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Metrics Definition | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Evaluation Methodology | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Monitoring Support | [0-25] | [Quote/reference from artifact] | [Assessment] |

**Function Score:** [0-100] (Average of aspects)

**Strengths:**
- [Specific strength with evidence]

**Gaps:**
- [Specific gap with recommendation]

---

### 4. MANAGE - Risk Treatment and Response

**Definition:** Implements controls, responds to identified risks, and monitors continuously.

**Evaluation Criteria:**
- Does artifact define or implement risk controls?
- Are mitigation strategies specified?
- Is incident response addressed?
- Does it support continuous risk management?

**Findings:**

| Aspect | Score (0-25) | Evidence | Notes |
|--------|--------------|----------|-------|
| Control Implementation | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Mitigation Strategy | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Incident Response | [0-25] | [Quote/reference from artifact] | [Assessment] |
| Continuous Management | [0-25] | [Quote/reference from artifact] | [Assessment] |

**Function Score:** [0-100] (Average of aspects)

**Strengths:**
- [Specific strength with evidence]

**Gaps:**
- [Specific gap with recommendation]

---

## Cross-Cutting Concerns

### Transparency and Documentation
**Score:** [0-100]  
**Assessment:** [How well does artifact support transparency requirements?]

### Interoperability and Standards
**Score:** [0-100]  
**Assessment:** [Does artifact align with ISO 42001, SP 800-53, EU AI Act, or other standards?]

### Usability and Adoption
**Score:** [0-100]  
**Assessment:** [Is artifact practical and likely to be adopted by target users?]

### Completeness and Accuracy
**Score:** [0-100]  
**Assessment:** [Is information complete, accurate, and up-to-date?]

---

## Detailed Recommendations

### Must Fix (Blocking Issues)
1. **[Issue]**
   - **Impact:** [Why this blocks approval]
   - **Remediation:** [Specific fix required]
   - **RMF Function Affected:** [Govern/Map/Measure/Manage]

### Should Fix (Important but Non-Blocking)
1. **[Issue]**
   - **Impact:** [Why this matters]
   - **Remediation:** [Suggested improvement]
   - **RMF Function Affected:** [Govern/Map/Measure/Manage]

### Nice to Have (Enhancements)
1. **[Suggestion]**
   - **Value:** [How this would improve artifact]
   - **RMF Function Affected:** [Govern/Map/Measure/Manage]

---

## Scoring Summary

| RMF Function | Score | Weight | Weighted Score |
|--------------|-------|--------|----------------|
| Govern | [0-100] | 25% | [score * 0.25] |
| Map | [0-100] | 25% | [score * 0.25] |
| Measure | [0-100] | 25% | [score * 0.25] |
| Manage | [0-100] | 25% | [score * 0.25] |
| **Base RMF Score** | | | **[Total]** |
| Cross-Cutting Average | [0-100] | 20% | [score * 0.20] |
| **Final Score** | | | **[Base + Cross-Cutting]** |

**Grade:**
- 90-100: Excellent - Exemplifies RMF best practices
- 80-89: Good - Solid RMF alignment with minor gaps
- 70-79: Acceptable - Meets minimum RMF requirements
- 60-69: Needs Improvement - Significant gaps in RMF coverage
- Below 60: Inadequate - Major RMF alignment issues

---

## Review Confidence and Limitations

**Reviewer Confidence Level:** [High / Medium / Low]

**Factors Affecting Confidence:**
- [Factor 1, e.g., "Full context available"]
- [Factor 2, e.g., "Limited domain expertise in X"]
- [Factor 3, e.g., "Ambiguity in artifact scope"]

**Known Limitations:**
- [Limitation 1, e.g., "Cannot verify external references"]
- [Limitation 2, e.g., "Subjective interpretation of criteria"]

**Recommended Follow-Up:**
- [Action 1, e.g., "Human expert review of technical claims"]
- [Action 2, e.g., "Multi-model consensus validation"]

---

## Appendix: Methodology Notes

**Evaluation Approach:**
[Describe how this review was conducted - what sources were consulted, what criteria were prioritized, what trade-offs were made in scoring]

**Scoring Calibration:**
- **0-25:** Absent or inadequate coverage of aspect
- **26-50:** Partial coverage with significant gaps
- **51-75:** Adequate coverage with minor improvements needed  
- **76-100:** Strong coverage demonstrating best practices

**Evidence Standards:**
- Direct quotes preferred for specific claims
- Paraphrasing acceptable for general patterns
- "Not addressed" explicitly noted when aspect is missing

---

**Review Completed:** [Date and Time]  
**Model Signature:** [Model identifier for traceability]  
**Human Verification Required:** Yes / No  
**File Location:** `evidence/exit-interviews/[artifact-name]-review-[YYYYMMDD].md`
